{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/mission_to_mars.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page. The following outlines what you need to do.\n",
    "\n",
    "\n",
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "\n",
    "   * Create a Jupyter Notebook file called <b>mission_to_mars.ipynb</b> and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "\n",
    "\n",
    "\n",
    "## NASA Mars News\n",
    "\n",
    "\n",
    "   * Scrape the  [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: \n",
    "       news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\" \n",
    "\n",
    "       news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for\n",
    "                 launch next May from Vandenberg Air Force Base in central California -- the first interplanetary\n",
    "                 launch in history from America's West Coast.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "\n",
    "\n",
    "  * Visit the url for JPL's Featured Space Image [here.](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars)<br><br>\n",
    "  * Use splinter to navigate the site and find the image url for the current \n",
    "    Featured Mars Image and assign the url    \n",
    "    string to a variable called <b>featured_image_url</b>.<br><br>\n",
    "  * Make sure to find the image url to the full size <b>.jpg</b> image.<br><br>\n",
    "  * Make sure to save a complete url string for this image.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather\n",
    "\n",
    "\n",
    "  * Visit the Mars Weather twitter account here and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called mars_weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "\n",
    "   * Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts \n",
    "     about the planet including Diameter, Mass, etc.<br></br>\n",
    "   * Use Pandas to convert the data to a HTML table string.<br></br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemisperes\n",
    "\n",
    "\n",
    "  * Visit the USGS Astrogeology site here to obtain high resolution images for each of Mar's hemispheres.<br></br>\n",
    "  \n",
    "  * You will need to click each of the links to the hemispheres in order to find the image url \n",
    "    to the full resolution image.<br></br>\n",
    "    \n",
    "  * Save both the image url string for the full resolution hemipshere image, and the Hemisphere title \n",
    "    containing the hemisphere name. Use a Python dictionary to store the data using the keys <b>img_url</b> and <b>title.</b> <br></br>\n",
    "   \n",
    "  * Append the dictionary with the image url string and the hemisphere title to a list. \n",
    "    This list will contain one dictionary for each hemisphere.<br></br>\n",
    "    \n",
    "    \n",
    "    \n",
    "### Example:\n",
    "hemisphere_image_urls = [\n",
    "\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - MongoDB and Flask Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "\n",
    "  * Start by converting your Jupyter notebook into a Python script called scrape_mars.py with a function called scrape that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "  * Next, create a route called /scrape that will import your scrape_mars.py script and call your scrape function.\n",
    "\n",
    "\n",
    "     * Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "\n",
    "  * Create a root route / that will query your Mongo database and pass the mars data into an HTML template to display the data.\n",
    "  * Create a template HTML file called index.html that will take the mars data dictionary and display all of the data in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/final_app_part1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/final_app_part2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints\n",
    "\n",
    "\n",
    " * Use splinter to navigate the sites when needed and BeautifulSoup to help find and parse out the necessary data.\n",
    " * Use Pymongo for CRUD applications for your database. For this homework, you can simply overwrite the existing document each time the /scrape url is visited and new data is obtained.\n",
    " * Use Bootstrap to structure your HTML template.\n",
    "\n",
    "\n",
    "\n",
    "Copyright\n",
    "\n",
    "Coding Boot Camp Â© 2017. All Rights Reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
